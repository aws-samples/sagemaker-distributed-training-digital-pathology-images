{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distributed training of tissue slide images using SageMaker and Horovod"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing input SVS image\n",
    "\n",
    "We need slideio for visualizing SVS images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install slideio===0.5.225\n",
    "!mkdir -p images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import boto3\n",
    "import slideio\n",
    "import matplotlib.pyplot as plt\n",
    "import sagemaker\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from sagemaker.processing import Processor, ProcessingInput, ProcessingOutput\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.tensorflow import TensorFlow\n",
    "from sagemaker.tensorflow.model import TensorFlowModel\n",
    "from sagemaker.session import s3_input\n",
    "\n",
    "role = get_execution_role()\n",
    "sagemaker_session = sagemaker.Session()\n",
    "region = boto3.Session().region_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = 'tcga-data' # Please specify the bucket where the tissues SVS images are downloaded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TCGA SVS files\n",
    "\n",
    "For downloading TCGA images, please refer to README file. Create a bucket in S3 and a folder `tcga-svs` within the bucket. This folder will contain all the SVS files.\n",
    "\n",
    "Replace the bucket name below with the name of the bucket you created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download sample svs file from S3\n",
    "s3 = boto3.resource('s3', region_name=region)\n",
    "\n",
    "image_file = 'TCGA-55-8514-01A-01-TS1.0e0f5cf3-96e9-4a35-aaed-4340df78d389.svs'\n",
    "key = f'tcga-svs/0000b231-7c05-4e2e-8c9e-6d0675bfbb34/{image_file}'\n",
    "\n",
    "s3.Bucket(bucket).download_file(key, f'./images/{image_file}')\n",
    "\n",
    "# Read svs image\n",
    "slide = slideio.open_slide(path=f\"./images/{image_file}\", driver=\"SVS\")\n",
    "scene = slide.get_scene(0)\n",
    "block = scene.read_block()\n",
    "\n",
    "# Display image\n",
    "plt.imshow(block,aspect=\"auto\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Docker container for preprocessing SVS files into TFRecord"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dockerfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pygmentize Dockerfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python script for preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pygmentize src/script.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build container and upload it to ECR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from docker_utils import build_and_push_docker_image\n",
    "\n",
    "repository_short_name = 'tcga-tissue-slides-preprocess'\n",
    "image_name = build_and_push_docker_image(repository_short_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Launch SageMaker Processing Job\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "processor = Processor(image_uri=image_name,\n",
    "                      role=get_execution_role(),\n",
    "                      instance_count=16,               # run the job on 16 instances\n",
    "                      base_job_name='processing-base', # should be unique name\n",
    "                      instance_type='ml.m5.4xlarge', \n",
    "                      volume_size_in_gb=1000)\n",
    "\n",
    "processor.run(inputs=[ProcessingInput(\n",
    "    source=f's3://{bucket}/tcga-svs', # s3 input prefix\n",
    "    s3_data_type='S3Prefix',\n",
    "    s3_input_mode='File',\n",
    "    s3_data_distribution_type='ShardedByS3Key', # Split the data across instances\n",
    "    destination='/opt/ml/processing/input')], # local path on the container\n",
    "    outputs=[ProcessingOutput(\n",
    "        source='/opt/ml/processing/output', # local output path on the container\n",
    "        destination=f's3://{bucket}/tcga-svs-tfrecords/' # output s3 location\n",
    "    )],\n",
    "    arguments=['10000'], # number of tiled images per TF record for training dataset\n",
    "    wait=True,\n",
    "    logs=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize tiled images within TF records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "print(tf.__version__)\n",
    "print(tf.executing_eagerly())\n",
    "\n",
    "HEIGHT=512\n",
    "WIDTH=512\n",
    "DEPTH=3\n",
    "NUM_CLASSES=3\n",
    "\n",
    "def dataset_parser(value):\n",
    "    image_feature_description = {\n",
    "        'label': tf.io.FixedLenFeature([], tf.int64),\n",
    "        'image_raw': tf.io.FixedLenFeature([], tf.string),\n",
    "        'slide_string': tf.io.FixedLenFeature([], tf.string)\n",
    "    }\n",
    "    record = tf.io.parse_single_example(value, image_feature_description)\n",
    "    image = tf.io.decode_raw(record['image_raw'], tf.float32)\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image.set_shape([DEPTH * HEIGHT * WIDTH])\n",
    "    image = tf.cast(tf.reshape(image, [HEIGHT, WIDTH, DEPTH]), tf.float32)\n",
    "    label = tf.cast(record['label'], tf.int32)\n",
    "    slide = record['slide_string']\n",
    "    \n",
    "    return image, label, slide\n",
    "\n",
    "# List first 10 tiled images\n",
    "\n",
    "key = 'tcga-svs-tfrecords/test'\n",
    "\n",
    "file = [f for f in s3.Bucket(bucket).objects.filter(Prefix=key).limit(1)][0]\n",
    "local_file = file.key.split('/')[-1]\n",
    "s3.Bucket(bucket).download_file(file.key, f'./images/{local_file}')\n",
    "\n",
    "raw_image_dataset = tf.data.TFRecordDataset(f'./images/{local_file}')\n",
    "parsed_image_dataset = raw_image_dataset.map(dataset_parser)\n",
    "\n",
    "c = 0\n",
    "for image_features in parsed_image_dataset:\n",
    "    image_raw = image_features[0].numpy()\n",
    "    label = image_features[1].numpy()\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.imshow(image_raw/255) \n",
    "    plt.title(f'Full image: {image_features[2].numpy().decode()}, Label: {label}')\n",
    "\n",
    "    c += 1\n",
    "    if c == 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distributed training with Horovod and Pipe Mode input\n",
    "Ditributed training with Horovod can also utilize SageMaker Pipe Mode.\n",
    "\n",
    "SageMaker Pipe Mode is a mechanism for providing S3 data to a training job via Linux fifos. Training programs can read from the fifo and get high-throughput data transfer from S3, without managing the S3 access in the program itself.\n",
    "Pipe Mode is covered in more detail in the SageMaker [documentation](https://sagemaker.readthedocs.io/en/stable/frameworks/tensorflow/using_tf.html#training-with-pipe-mode-using-pipemodedataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_instance_type='ml.p3.8xlarge'\n",
    "train_instance_count = 4\n",
    "gpus_per_host = 4\n",
    "num_of_shards = gpus_per_host * train_instance_count\n",
    "\n",
    "distributions = {'mpi': {\n",
    "    'enabled': True,\n",
    "    'processes_per_host': gpus_per_host\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sharding the tiles "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sharding\n",
    "client = boto3.client('s3')\n",
    "result = client.list_objects(Bucket=bucket, Prefix='tcga-svs-tfrecords/train/', Delimiter='/')\n",
    "\n",
    "j = -1\n",
    "for i in range(num_of_shards):\n",
    "    copy_source = {\n",
    "        'Bucket': bucket,\n",
    "        'Key': result['Contents'][i]['Key']\n",
    "     }\n",
    "    print(result['Contents'][i]['Key'])\n",
    "    if i%4 == 0:\n",
    "        j += 1\n",
    "    dest = 'tcga-svs-tfrecords/train_sharded/' + str(j) +'/' + result['Contents'][i]['Key'].split('/')[2]\n",
    "    print(dest)\n",
    "    s3.meta.client.copy(copy_source, bucket, dest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svs_tf_sharded = f's3://{bucket}/tcga-svs-tfrecords'\n",
    "shuffle_config = sagemaker.session.ShuffleConfig(234)\n",
    "train_s3_uri_prefix = svs_tf_sharded\n",
    "remote_inputs = {}\n",
    "\n",
    "for idx in range(4):\n",
    "    train_s3_uri = f'{train_s3_uri_prefix}/train_sharded/{idx}/'\n",
    "    train_s3_input = s3_input(train_s3_uri, distribution ='ShardedByS3Key', shuffle_config=shuffle_config)\n",
    "    remote_inputs[f'train_{idx}'] = train_s3_input\n",
    "    remote_inputs['valid_{}'.format(idx)] = '{}/valid'.format(svs_tf_sharded)\n",
    "remote_inputs['test'] = '{}/test'.format(svs_tf_sharded)\n",
    "remote_inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pygmentize src/train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "local_hyperparameters = {'epochs': 5, 'batch-size' : 16, 'num-train':160000, 'num-val':8192, 'num-test':8192}\n",
    "\n",
    "estimator_dist = TensorFlow(base_job_name='svs-horovod-cloud-pipe',\n",
    "                            entry_point='src/train.py',\n",
    "                            role=role,\n",
    "                            framework_version='2.1.0',\n",
    "                            py_version='py3',\n",
    "                            distribution=distributions,\n",
    "                            volume_size=1024,\n",
    "                            hyperparameters=local_hyperparameters,\n",
    "                            output_path=f's3://{bucket}/output/',\n",
    "                            instance_count=4, \n",
    "                            instance_type=train_instance_type,\n",
    "                            input_mode='Pipe')\n",
    "\n",
    "estimator_dist.fit(remote_inputs, wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy the trained model\n",
    "\n",
    "The deploy() method creates an endpoint that serves prediction requests in real-time.\n",
    "The model saves keras artifacts, to use TensorFlow serving for deployment, you'll need to save the artifacts in SavedModel format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "plt.style.use('bmh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create predictor from S3 instead\n",
    "\n",
    "model_data = f's3://{bucket}/output/{estimator_dist.latest_training_job.name}/output/model.tar.gz'\n",
    "\n",
    "model = TensorFlowModel(model_data=model_data, \n",
    "                        role=role, framework_version='2.1.0')\n",
    "\n",
    "predictor = model.deploy(initial_instance_count=1, instance_type='ml.c5.xlarge')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make some predictions\n",
    "To verify the that the endpoint functions properly, we generate random data in the correct shape and get a prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HEIGHT=512\n",
    "WIDTH=512\n",
    "DEPTH=3\n",
    "NUM_CLASSES=3\n",
    "\n",
    "def _dataset_parser_with_slide(value):\n",
    "    image_feature_description = {\n",
    "        'label': tf.io.FixedLenFeature([], tf.int64),\n",
    "        'image_raw': tf.io.FixedLenFeature([], tf.string),\n",
    "        'slide_string': tf.io.FixedLenFeature([], tf.string)\n",
    "    }\n",
    "    example = tf.io.parse_single_example(value, image_feature_description)\n",
    "    image = tf.io.decode_raw(example['image_raw'], tf.float32)\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image.set_shape([DEPTH * HEIGHT * WIDTH])\n",
    "    image = tf.cast(tf.reshape(image, [HEIGHT, WIDTH, DEPTH]), tf.float32)\n",
    "    label = tf.cast(example['label'], tf.int32)\n",
    "    slide = example['slide_string']\n",
    "    \n",
    "    return image, label, slide"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tile-level prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "local_file = [each for each in os.listdir('./images') if each.endswith('.tfrecords')][0]\n",
    "\n",
    "raw_image_dataset = tf.data.TFRecordDataset(f'./images/{local_file}') ## read a TFrecord\n",
    "parsed_image_dataset = raw_image_dataset.map(_dataset_parser_with_slide) ## Parse TFrecord to JPEGs\n",
    "\n",
    "pred_scores_list = []\n",
    "for i, element in enumerate(parsed_image_dataset):\n",
    "    if i > 10:\n",
    "        break\n",
    "    image = element[0].numpy()\n",
    "    label = element[1].numpy()\n",
    "    slide = element[2].numpy().decode()\n",
    "    if i == 0:\n",
    "        print(f'Making tile-level predictions for slide: {slide}...')\n",
    "\n",
    "    print(f'Querying endpoint for a prediction for tile {i+1}...')\n",
    "    pred_scores = predictor.predict(np.expand_dims(image, axis=0))['predictions'][0]\n",
    "    print(pred_scores)\n",
    "    pred_class = np.argmax(pred_scores) \n",
    "    print(pred_class)\n",
    "       \n",
    "    if i > 0 and i % 10 == 0:\n",
    "        plt.figure()\n",
    "        plt.title(f'Tile {i} prediction: {pred_class}')  \n",
    "        plt.imshow(image / 255)\n",
    "         \n",
    "    pred_scores_list.append(pred_scores)\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slide-level prediction (average score over all tiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_pred_scores = np.mean(np.vstack(pred_scores_list), axis=0)\n",
    "mean_pred_class = np.argmax(mean_pred_scores)\n",
    "\n",
    "print(f\"Slide-level prediction for {slide}:\", mean_pred_class)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow2_p36",
   "language": "python",
   "name": "conda_tensorflow2_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
